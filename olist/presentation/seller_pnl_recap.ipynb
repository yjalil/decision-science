{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seller P&L Analyis + GeoPandas üåé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ The goal of this exercise is to compute the P&L associated to each seller  \n",
    "\n",
    "For each `seller_id` we need three items:  \n",
    "\n",
    "- The **revenue**:\n",
    " - 10% fee on sales\n",
    " - 80 BRL per month on Olist\n",
    "\n",
    "\n",
    "- The **cost**:\n",
    " - Review cost according to `{1: 100, 2: 50, 3: 40, 4: 0, 5: 0}` with review score as key and cost in BRL as value\n",
    "\n",
    "\n",
    "- The **profit** made by Olist\n",
    "\n",
    "üí° Let's not start from scratch  \n",
    "‚ùì Import your seller training set and investigate what you already have.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "from olist.seller import Seller\n",
    "seller = Seller()\n",
    "sellers = seller.get_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "delete"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seller_id</th>\n",
       "      <th>seller_city</th>\n",
       "      <th>seller_state</th>\n",
       "      <th>delay_to_carrier</th>\n",
       "      <th>wait_time</th>\n",
       "      <th>date_first_sale</th>\n",
       "      <th>date_last_sale</th>\n",
       "      <th>months_on_olist</th>\n",
       "      <th>n_orders</th>\n",
       "      <th>quantity</th>\n",
       "      <th>quantity_per_order</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3442f8959a84dea7ee197c632cb2df15</td>\n",
       "      <td>campinas</td>\n",
       "      <td>SP</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.018588</td>\n",
       "      <td>2017-05-05 16:25:11</td>\n",
       "      <td>2017-08-30 12:50:19</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000</td>\n",
       "      <td>218.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d1b65fc7debc3361ea86b5f14c68d2e2</td>\n",
       "      <td>mogi guacu</td>\n",
       "      <td>SP</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.065716</td>\n",
       "      <td>2017-03-29 02:10:34</td>\n",
       "      <td>2018-06-06 20:15:21</td>\n",
       "      <td>14.0</td>\n",
       "      <td>40</td>\n",
       "      <td>41</td>\n",
       "      <td>1.025</td>\n",
       "      <td>11703.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ce3ad9de960102d0677a81f5d0bb7b2d</td>\n",
       "      <td>rio de janeiro</td>\n",
       "      <td>RJ</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.042292</td>\n",
       "      <td>2018-07-30 12:44:49</td>\n",
       "      <td>2018-07-30 12:44:49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>158.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c0f3eea2e14555b6faeea3dd58c1b1c3</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.667187</td>\n",
       "      <td>2018-08-03 00:44:08</td>\n",
       "      <td>2018-08-03 00:44:08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51a04a8a6bdcb23deccc82b0b80742cf</td>\n",
       "      <td>braganca paulista</td>\n",
       "      <td>SP</td>\n",
       "      <td>3.353727</td>\n",
       "      <td>35.314861</td>\n",
       "      <td>2017-11-14 12:15:25</td>\n",
       "      <td>2017-11-14 12:15:25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>167.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          seller_id        seller_city seller_state  \\\n",
       "0  3442f8959a84dea7ee197c632cb2df15           campinas           SP   \n",
       "1  d1b65fc7debc3361ea86b5f14c68d2e2         mogi guacu           SP   \n",
       "2  ce3ad9de960102d0677a81f5d0bb7b2d     rio de janeiro           RJ   \n",
       "3  c0f3eea2e14555b6faeea3dd58c1b1c3          sao paulo           SP   \n",
       "4  51a04a8a6bdcb23deccc82b0b80742cf  braganca paulista           SP   \n",
       "\n",
       "   delay_to_carrier  wait_time     date_first_sale      date_last_sale  \\\n",
       "0          0.000000  13.018588 2017-05-05 16:25:11 2017-08-30 12:50:19   \n",
       "1          0.000000   9.065716 2017-03-29 02:10:34 2018-06-06 20:15:21   \n",
       "2          0.000000   4.042292 2018-07-30 12:44:49 2018-07-30 12:44:49   \n",
       "3          0.000000   5.667187 2018-08-03 00:44:08 2018-08-03 00:44:08   \n",
       "4          3.353727  35.314861 2017-11-14 12:15:25 2017-11-14 12:15:25   \n",
       "\n",
       "   months_on_olist  n_orders  quantity  quantity_per_order     sales  \n",
       "0              4.0         3         3               1.000    218.70  \n",
       "1             14.0        40        41               1.025  11703.07  \n",
       "2              0.0         1         1               1.000    158.00  \n",
       "3              0.0         1         1               1.000     79.99  \n",
       "4              0.0         1         1               1.000    167.99  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sellers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì What is missing?  \n",
    "Write down a strategy to get your missing columns  \n",
    "Re-use as much of what has already been coded in `seller.py` as possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Make a copy of `seller.py`, rename it `seller_updated.py` and update it accordingly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "delete"
    ]
   },
   "source": [
    "Correction below is equivalent to the `get_review_score` method in `seller_updated.py`\n",
    "\n",
    "Show students how to update their code and print results in their notebook  \n",
    "Debug using `breakpoint()` when needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "source": [
    "```python\n",
    "def get_review_score(self):\n",
    "    \"\"\"\n",
    "    Returns a DataFrame with:\n",
    "    'seller_id', 'share_of_five_stars', 'share_of_one_stars', 'review_score', 'cost_of_reviews'\n",
    "    \"\"\"\n",
    "\n",
    "    orders_reviews = self.order.get_review_score()\n",
    "    orders_sellers = self.data['order_items'][['order_id', 'seller_id'\n",
    "                                               ]].drop_duplicates()\n",
    "\n",
    "    df = orders_sellers.merge(orders_reviews, on='order_id')\n",
    "\n",
    "    df['cost_of_review'] = df.review_score.map({\n",
    "        1: 100,\n",
    "        2: 50,\n",
    "        3: 40,\n",
    "        4: 0,\n",
    "        5: 0\n",
    "    })\n",
    "\n",
    "    df_grouped_by_sellers = df.groupby('seller_id', as_index=False).agg({\n",
    "        'dim_is_one_star':\n",
    "        'mean',\n",
    "        'dim_is_five_star':\n",
    "        'mean',\n",
    "        'review_score':\n",
    "        'mean',\n",
    "        'cost_of_review':\n",
    "        'sum'\n",
    "    })\n",
    "    df_grouped_by_sellers.columns = [\n",
    "        'seller_id', 'share_of_one_stars', 'share_of_five_stars',\n",
    "        'review_score', 'cost_of_reviews'\n",
    "    ]\n",
    "\n",
    "    return df_grouped_by_sellers\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Compute seller profits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "source": [
    "```python\n",
    "def get_training_data(self):\n",
    "    \"\"\"\n",
    "    Returns a DataFrame with:\n",
    "    ['seller_id', 'seller_city', 'seller_state', 'delay_to_carrier',\n",
    "    'wait_time', 'date_first_sale', 'date_last_sale', 'months_on_olist',\n",
    "    'share_of_one_stars', 'share_of_five_stars', 'review_score',\n",
    "    'cost_of_reviews', 'n_orders', 'quantity', 'quantity_per_order',\n",
    "    'sales', 'revenues', 'profits']\n",
    "    \"\"\"\n",
    "    training_set =\\\n",
    "        self.get_seller_features()\\\n",
    "            .merge(\n",
    "            self.get_seller_delay_wait_time(), on='seller_id'\n",
    "        ).merge(\n",
    "            self.get_active_dates(), on='seller_id'\n",
    "        ).merge(\n",
    "            self.get_review_score(), on='seller_id'\n",
    "        ).merge(\n",
    "            self.get_quantity(), on='seller_id'\n",
    "        ).merge(\n",
    "            self.get_sales(), on='seller_id'\n",
    "        )\n",
    "\n",
    "    # Add seller economics (revenues, profits)\n",
    "    olist_monthly_fee = 80\n",
    "    olist_sales_cut = 0.1\n",
    "\n",
    "    training_set['revenues'] = training_set['months_on_olist'] * olist_monthly_fee\\\n",
    "        + olist_sales_cut * training_set['sales']\n",
    "\n",
    "    training_set['profits'] = training_set['revenues'] - training_set[\n",
    "        'cost_of_reviews']\n",
    "\n",
    "    return training_set\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Load your updated DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'olist.seller_updated'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01molist\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mseller_updated\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Seller \u001b[38;5;28;01mas\u001b[39;00m SellerUpdated\n\u001b[1;32m      2\u001b[0m sellers \u001b[38;5;241m=\u001b[39m SellerUpdated()\u001b[38;5;241m.\u001b[39mget_training_data()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'olist.seller_updated'"
     ]
    }
   ],
   "source": [
    "from olist.seller_updated import Seller as SellerUpdated\n",
    "sellers = SellerUpdated().get_training_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Sort sellers by profit, and analyse their profitability: conclude on a possible strategy for Olist!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "sorted_sellers = sellers.sort_values(by='profits')[['profits', 'n_orders', 'revenues']].reset_index()\n",
    "sorted_sellers.head()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sorted_sellers.profits.plot()\n",
    "plt.title('gross profit per seller')\n",
    "plt.xlabel('seller id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "# Optional Bonus: GeoPandas\n",
    "\n",
    "For any students looking for some alternative/more advanced ways to carry out and present their analysis, we can check out some GeoPandas code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install geopandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is [GeoPandas](https://geopandas.org/en/stable/index.html)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GeoPandas is a Python module that adds geospatial capabilities to the popular Pandas library. üåç It's like a magic wand for working with geographical data, allowing you to manipulate, analyze, and visualize geospatial datasets with ease. üìä \n",
    "\n",
    "With GeoPandas, you can load and save various geospatial file formats:\n",
    "- (Shapefile (.shp)\n",
    "- GeoJSON (.geojson)\n",
    "- GeoPackage (.gpkg)\n",
    "- KML (.kml)\n",
    "- GeoTIFF (.tif)\n",
    "\n",
    "Once loaded, you can perform spatial operations like intersections and buffers, and create beautiful maps to showcase your findings. üé® It builds upon powerful geospatial libraries like Shapely and Fiona, providing a comprehensive toolset for all your geospatial needs üí™ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Basic usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to libraries like Seaborn, GeoPandas has its own demo datasets we can have a quick play with!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the Natural Earth cities dataset\n",
    "world_df = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "\n",
    "# Print the loaded data\n",
    "world_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to plot our geometry out, all we have to do is call .plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use our population column to add some color by specifying `column =` in our `.plot()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_df.plot(column  = \"pop_est\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can overlay two plots on top of each other very easily, too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Natural Earth cities dataset\n",
    "cities_df = gpd.read_file(gpd.datasets.get_path('naturalearth_cities'))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot the world map + cities\n",
    "world_df.plot(ax=ax, color='lightgray')\n",
    "cities_df.plot(ax=ax, marker='o', color='red', markersize=5)\n",
    "\n",
    "# Set our title\n",
    "plt.title('Cities Overlaid on World Map')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this is all you have time for, hop to the end to see an Olist example!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part Two: London Tube Investigation! \n",
    "\n",
    "First, download [this folder](https://wagon-public-datasets.s3.amazonaws.com/data-science-images/geopandas_decision_science/data.zip) and put it into a `data` folder in this directory. Let's load up a the `London_Ward.shp` shapefile (if you look in the folder you'll see it's split into a few parts - see [this](https://en.wikipedia.org/wiki/Shapefile) for why!) for London's regions and also our locations for tube stops (`london-underground.geojson`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "london_stations = gpd.read_file(\"data/london-underground.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "london_map = gpd.read_file(\"data/London_Ward.shp\")\n",
    "london_map.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "london_map.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we have a few too many wards. What we're more interested in is the Districts. Let's use `.dissolve(by = \"DISTRICT\")` to merge our District shapes together. You can think of it like a geospatial groupby!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "london_districts = london_map.dissolve(by = \"DISTRICT\", as_index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "london_districts.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks more reasonable! Let's overlay our tube stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "london_districts.plot(ax = ax)\n",
    "london_stations.plot(ax = ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That doesn't look right üò¨  This often occurs when our geometries have been saved on different projections. Let's use `.crs` to check!\n",
    "\n",
    "üåç Coordinate Reference Systems (CRS) in GeoPandas are like the Earth's GPS coordinates system. They provide a way to precisely locate and interpret spatial data. üó∫Ô∏è A CRS consists of a coordinate system and a datum, ensuring that geographic features are accurately represented on maps. It also allows for transformations between different CRSs, so you can project or reproject data to fit specific needs. üîÄ With CRS, GeoPandas helps you navigate the spatial world, ensuring your data aligns correctly and enabling you to explore and analyze geographic information effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(london_districts.crs)\n",
    "print(london_stations.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's change the projection of our stations to match our districts and try again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "london_stations = london_stations.to_crs(\"EPSG:27700\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(london_districts.crs)\n",
    "print(london_stations.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like they're aligned; let's visualize to check!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "london_districts.plot(ax = ax)\n",
    "london_stations.plot(ax = ax, markersize = 2, color = \"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better! Now let's use [`.buffer()`](https://geopandas.org/en/stable/docs/reference/api/geopandas.GeoSeries.buffer.html) to see how much area is within an 800m walk of a tube station!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_buffer = london_stations.buffer(800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does our buffered out area look like? What's its total area?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "london_districts.plot(ax = ax)\n",
    "station_buffer.plot(ax = ax, color = \"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find its area we can simply use `.unary_union` (which blends all of our shapes together) and then `.area`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total area within 800m of a station is: {station_buffer.unary_union.area} square meters \\\n",
    "or {station_buffer.unary_union.area / 1_000_000} square km\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, we can look at which areas are best and worst served!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to dissolve our buffer geometries all into one large shape. But we can only call use the `.dissolve()` method on a GeoDataFrame and our `station_buffer` is a `GeoSeries`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(station_buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So first we convert to a `GeoDataFrame` (by simply writing `GeoDataFrame(<our_series>)`) and then we can call `.dissolve()`\n",
    "\n",
    "N.B. When converting to a GeoDataFrame, we also have to specify that our geometry is in our first - and only column - by writing `geometry = 0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_df = gpd.GeoDataFrame(station_buffer, geometry=0).dissolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our final step is to use the `.overlay()` function with the `\"intersection\"` argument. This will return to us the intersection between our two GeoDataFrames on a district by district basis! Then create our final column in our DataFrame as the area of the geometry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://wagon-public-datasets.s3.amazonaws.com/data-science-images/gpd_overlays.webp\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_overlap = gpd.overlay(buffer_df,london_districts, how='intersection')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can plot out one district!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "london_districts.plot(ax = ax)\n",
    "# Here we're just selecting the geometry with our second district (Camden)\n",
    "gdf_overlap.loc[[1],'geometry'].plot(ax = ax,color = \"white\")\n",
    "plt.title('Camden tube coverage')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All that's left is to create a new column which describes the area of each of our polygons so we can say how much of each DISTRICT was covered by our tubes! Creating new columns works just like it does in Pandas and all we need to do is access the `.area` attribute of our column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_overlap[\"area_covered\"] = gdf_overlap[\"geometry\"].area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we merge it all into one GeoDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = london_districts.merge(gdf_overlap[[\"DISTRICT\", \"area_covered\"]], on = \"DISTRICT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the overall area of each district:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[\"total_area\"] = merged.geometry.area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And divide!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[\"percentage_covered\"] = (merged[\"area_covered\"] / merged[\"total_area\"]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[[\"DISTRICT\", \"percentage_covered\"]].sort_values(by = \"percentage_covered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How can we apply this to Olist? \n",
    "\n",
    "Well, for starters we can make some great plots. Run the cells below to generate a map of Brazil with NPS overlaid. Where you go from here is your choice tomorrow üí™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from olist.data import Olist\n",
    "from olist.order import Order\n",
    "import matplotlib.pyplot as plt\n",
    "data = Olist().get_data()\n",
    "orders = Order().get_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate NPS score per state\n",
    "merge = data['orders'].merge(data['order_reviews'], on='order_id')\\\n",
    "                      .merge(data['customers'], on='customer_id')\n",
    "\n",
    "by_state_nps = merge.groupby(['customer_state'], as_index=False)['review_score'] \\\n",
    "                    .apply(lambda s: s.map({5:1, 4:0, 3:-1, 2:-1, 1:-1}).sum() / s.count()) \\\n",
    "                    .rename(columns={\"review_score\":\"average_nps\"})\n",
    "\n",
    "nps_brazil = orders.review_score.map({5:1, 4:0, 3:-1, 2:-1, 1:-1}).sum() / orders.review_score.count()\n",
    "\n",
    "# Preprocess GeoDataFrame\n",
    "brazil = gpd.read_file('https://wagon-public-datasets.s3.amazonaws.com/04-Decision-Science/04-Logistic-Regression/brazil.gpkg')\n",
    "brazil.rename({\"sigla\": 'customer_state'}, axis=1, inplace=True)\n",
    "brazil_nps = brazil.merge(by_state_nps, on='customer_state', how='left')\n",
    "brazil_nps = brazil_nps[['customer_state', 'average_nps', 'geometry']]\n",
    "brazil_nps['center_x'] = brazil_nps['geometry'].map(lambda c: c.centroid.x)\n",
    "brazil_nps['center_y'] = brazil_nps['geometry'].map(lambda c: c.centroid.y)\n",
    "\n",
    "# Plot figure\n",
    "fig, ax = plt.subplots(figsize=(11,7))\n",
    "brazil_nps.plot(column = \"average_nps\",\n",
    "                   cmap='RdBu',\n",
    "                   legend=True,\n",
    "                   edgecolor='black',\n",
    "                   ax=ax,\n",
    "                   label='Average nps per state')\n",
    "\n",
    "# Labeling and styling the plot\n",
    "ax.set_xlabel(\"Latitude\", labelpad=10)\n",
    "ax.set_ylabel(\"Longitude\", labelpad=10)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "ax.set_title('Average net promoter score (NPS per state)', pad=10, size=16)\n",
    "\n",
    "ax.text(-48,-32,f'Brazil NPS Score = {nps_brazil*100:.1f}%', size=12)\n",
    "\n",
    "#Annotating each state's name on to the centre of the state's geometry\n",
    "for idx, row in brazil_nps.iterrows():\n",
    "    ax.text(row[\"center_x\"], row[\"center_y\"],row[\"customer_state\"], ha=\"center\", va=\"center\")\n",
    "\n",
    "plt.show();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
